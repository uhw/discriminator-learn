{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet at 0x112b8c4e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discriminator(images, reuse=False):\n",
    "    \"\"\"\n",
    "        From tutorial: https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners\n",
    "    \"\"\"\n",
    "    if (reuse):\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "    # First convolutional and pool layers\n",
    "    # This finds 32 different 5 x 5 pixel features\n",
    "    # Create a 5x5 4d tensor. 5 x 5 x 1 is the pixel patch size (5 x 5) with 1 color chanel\n",
    "    #                         32 is the output.\n",
    "    d_w1 = tf.get_variable('d_w1', shape=[5, 5, 1, 32], dtype=tf.float32,\n",
    "                           initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "    # Bias for each of the 32 outputs.\n",
    "    d_b1 = tf.get_variable('d_b1', shape=[32], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "    \n",
    "    d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d1 = tf.add(d1, d_b1)\n",
    "    d1 = tf.nn.relu(d1)\n",
    "    d1 = tf.nn.max_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Second convolutional and pool layers\n",
    "    # This finds 64 different 5 x 5 pixel features\n",
    "    d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "    d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d2 = tf.add(d2, d_b2)\n",
    "    d2 = tf.nn.relu(d2)\n",
    "    d2 = tf.nn.max_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # First fully connected layer\n",
    "    d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "    d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "    d3 = tf.matmul(d3, d_w3)\n",
    "    d3 = d3 + d_b3\n",
    "    d3 = tf.nn.relu(d3)\n",
    "\n",
    "    # Second fully connected layerkeras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)\n",
    "\n",
    "    d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "    d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "\n",
    "    # d4 contains unscaled values\n",
    "    return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keras_discriminator():\n",
    "    \"\"\"\n",
    "        Translation of tutorial into Keras.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(28, 28, 1))\n",
    "    layer = Conv2D(filters=32, kernel_size=(5, 5), activation=\"relu\")(inputs)\n",
    "    layer = MaxPool2D()(layer)\n",
    "    layer = Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\")(layer)\n",
    "    layer = MaxPool2D()(layer)\n",
    "    \n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(units=512, activation=\"relu\")(layer)\n",
    "    outputs = Dense(units=10, activation=\"softmax\")(layer)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=\"adam\", \n",
    "              metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44000 samples, validate on 11000 samples\n",
      "Epoch 1/10\n",
      "44000/44000 [==============================] - 56s - loss: 0.1726 - acc: 0.9476 - val_loss: 0.0541 - val_acc: 0.9836\n",
      "Epoch 2/10\n",
      "44000/44000 [==============================] - 55s - loss: 0.0463 - acc: 0.9852 - val_loss: 0.0462 - val_acc: 0.9867\n",
      "Epoch 3/10\n",
      "44000/44000 [==============================] - 55s - loss: 0.0302 - acc: 0.9907 - val_loss: 0.0393 - val_acc: 0.9878\n",
      "Epoch 4/10\n",
      "44000/44000 [==============================] - 55s - loss: 0.0212 - acc: 0.9935 - val_loss: 0.0518 - val_acc: 0.9860\n",
      "Epoch 5/10\n",
      "44000/44000 [==============================] - 55s - loss: 0.0167 - acc: 0.9944 - val_loss: 0.0347 - val_acc: 0.9903\n",
      "Epoch 6/10\n",
      "44000/44000 [==============================] - 55s - loss: 0.0132 - acc: 0.9957 - val_loss: 0.0348 - val_acc: 0.9906\n",
      "Epoch 7/10\n",
      "44000/44000 [==============================] - 55s - loss: 0.0109 - acc: 0.9965 - val_loss: 0.0463 - val_acc: 0.9894\n",
      "Epoch 8/10\n",
      "44000/44000 [==============================] - 55s - loss: 0.0094 - acc: 0.9968 - val_loss: 0.0445 - val_acc: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12b042208>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = keras_discriminator()\n",
    "d.fit(x=mnist.train.images.reshape((mnist.train.images.shape[0], 28, 28, 1)),\n",
    "      y=np_utils.to_categorical(mnist.train.labels),\n",
    "      batch_size=100,\n",
    "      epochs=10,\n",
    "      callbacks=[EarlyStopping(patience=2)],\n",
    "      validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9952/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "err = d.evaluate(x=mnist.test.images.reshape((mnist.test.images.shape[0], 28, 28, 1)),\n",
    "           y=np_utils.to_categorical(mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate:  0.0101\n"
     ]
    }
   ],
   "source": [
    "print(\"error rate: \", 1 - err[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_size(w, k, p, s):\n",
    "    return (w - k + 2 * p) / s + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size(28, 5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size(24, 2, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size(12, 5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_utils.to_categorical(mnist.train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
